---
author: David Carslaw
editor_options: 
  markdown: 
    wrap: 72
abstract: This section outlines the different ways users can access the abundant air quality data in the UK. The main functions provide easy access to hourly data and other statistical summaries such as annual means and data capture rates. Easy access is also provided to site meta data such as longitude, latitude, site type and details of the pollutants measured.
---

# 获取英国空气质量数据 {#sec-importUKAQ}

## 获取监测数据

英国有大量可公开访问的空气质量数据。其中最重要的几个大型数据库都可以免费访问，包括英国AURN全国数据库、地区（英格兰、苏格兰、威尔士和北爱尔兰）数据库以及伦敦帝国理工学院的伦敦空气质量监测网（LAQN）等。以上这几个大型数据库都可以保证统一的数据格式和高标准的数据质量。

[openair]{.pkg} 为用户获取英国空气质量监测数据提供了一个重要函数；`importUKAQ()`。里卡多能源与环境咨询公司还制作了包含英国几大空气质量监测网数据的.RData 文件（R工作区），并以日为单位持续更新。非常感谢里卡多能源与环境咨询公司的Trevor Davies为此所作的大量工作。这种数据访问方式需要互联网公网环境才能工作。通过 `importUKAQ()`可访问的监测网络数据包括： 

-   英国国家网数据 [AURN 城乡自动监测网](https://uk-air.defra.gov.uk/networks/network-info?view=aurn)，这是英国最主要的监测网络。

-   英国的“地区”监测网络：

    -   [苏格兰空气质量监测网络](http://www.scottishairquality.scot/) 数据。

    -   [威尔士空气质量监测网络](https://airquality.gov.wales/) 数据。

    -   [英格兰空气质量监测网络](https://www.airqualityengland.co.uk/) 站点数据。

    -   [北爱尔兰空气质量监测网络](https://www.airqualityni.co.uk) 站点数据。

-   英国境内地方管理的空气质量监测网。地方监测站点大部分由当地政府运行，也包括对特定项目、工业和机场等的监测站点。这些站点的选址和监测目的可能和严格按照技术规定组织监测的国家网站点有所不同，所以会存在更广泛的站点类型、设备类型和数据质量要求。更多信息请访问[这里](https://uk-air.defra.gov.uk/networks/network-info?view=nondefraaqmon)。这个数据源的数据大概包含了15个不同的地方空气质量监测网。

还有一个`importKCL`函数，专门用于获取由伦敦帝国理工大学[^uk-air-quality-data-1]运行的站点的数据，主要包括的是[伦敦市空气质量监测网](https://www.londonair.org.uk/LondonAir/Default.aspx)。

[^uk-air-quality-data-1]: The data were first accessible when the
    Environmental Research Group was based at King's College London.

多数用户会通过[英国空气质量](https://uk-air.defra.gov.uk/data/)来下载空气质量小时数据。一般情况下，数据会以固定的格式将 .csv 文件用过电子邮件发给用户。这种方法可行但是同时也有一些局限性，我们将在下文介绍一种新的数据下载和存储方式。

相比于通过网站下载 .csv 文件的方式，新方法有以下几点优势。首先，选择一组站点、污染物和时间段（后面会详细介绍）更便捷。其次，将数据存储为 .Rdata 对象其文件大小只有 .csv文件（已经比较小了）的四分之一，这意味着节省网络带宽和本次存储空间。第三，获取函数会自动进行一系列数据处理操作，比如设置时间格式和时区等。最后，一次性下载和导入多年的数据更方便，这可以帮助我们比较轻松的获取多个站点的长时间序列数据。

站点的编码和污染物名称可以是大写或者小写字母。

后面会通过案例介绍具体使用方法。现在先加载我们需要的软件包。

```{r}
#| warning: false
#| message: false
#| cache: false
library(openair)
library(tidyverse)
```

## 站点元数据

### 国家监测网

下载数据前我们需要了解的首先是：有哪些站点？监测了哪些污染物？用户可以通过 `importMeta()` 函数获得空气质量监测站点的详细信息。用户是需要梯提供想要了解的监测网络的名称和（可选的）是否返回所有站点属性数据以及关注的时间段即可。缺省状态下，除站名外只返回站点类型和站点经纬度坐标。

```{r}
#| label: importMeta
#| warning: false
#| message: false
aurn_meta <- importMeta(source = "aurn")
aurn_meta
```

添加 `all = TRUE` 选项可以得到完整详细的站点信息，包括每个站点都监测哪些污染物，监测的气质日期等等。

```{r}
#| label: importMetaAll
#| eval: true
aurn_meta <- importMeta(source = "aurn", all = TRUE)

# what comes back?
glimpse(aurn_meta)
```

`importMeta()`也可以同时获取几个监测网络的站点元数据，如：`source = c("aurn", "saqn")`

在进行长期趋势分析的时候，我们需要找到知道监测网络中哪些站点的连续监测能够完整的覆盖分析时段。这时需要用 `year` 参数来筛选出在特定年份或特定多年（如 `year = 2010:2020`）有完整监测的站点。此外，通过同时加入 `all = TRUE` 得到完整信息，可以进一步得到在那一年（或那几年）某项污染物有完整监测的站点。[^uk-air-quality-data-2]

[^uk-air-quality-data-2]: 一个站点可能已经运行了很多年，但是并不一定所有的污染物都是从建站那一天起就开始监测的。

下面的示例代码可在AURN和SAQN两个监测网络中查询在2010到2022年持续运行的站点的个数：

```{r}
sites_2010_2022 <- importMeta(
  source = c("aurn", "saqn"),
  year = 2010:2022
)

nrow(sites_2010_2022)
```

下面的例子是用AURN网的站点清单中进一步筛选出有NO~2~监测项目的电脑，这种方法也适用于从其它渠道得到的站点清单。

AURN网中监测NO~2~的站点中属于交通环境监测点的有多少个：

```{r}
#| warning: false
#| message: false
aurn_detailed <- importMeta(source = "aurn", all = TRUE)

no2_sites <- filter(
  aurn_detailed,
  variable == "NO2",
  site_type == "Urban Traffic"
)

nrow(no2_sites)
```

::: callout-tip
## 使用 `importMeta()` 作为数据导入过程中选择站点的工具

`importMeta()` 的一个重要用途是生成一个需要导入数据的站点编码的列表。例如：从AURN网导入在2005-2020年运行的站点是数据：

```{r}
#| eval: false
sites_2005_2020 <- importMeta(
  source = "aurn",
  year = 2005:2020
)

all_aq_data <- importUKAQ(
  site = sites_2005_2020$code,
  year = 2005:2020
)
```
:::

接下来就可以用 `importUKAQ()` 函数来获取数据了。下面展示了几种不同形式的用法。

```{r}
#| eval: false
## import all pollutants from Marylebone Rd from 2000:2005
mary <- importUKAQ(site = "my1", year = 2000:2005)

## import nox, no2, o3 from Marylebone Road and Nottingham Centre for 2000
thedata <- importUKAQ(
  site = c("my1", "nott"), year = 2000,
  pollutant = c("nox", "no2", "o3")
)

## import over 30 years of Mace Head O3 data!
o3 <- importUKAQ(site = "mh", year = 1987:2019)

## import hydrocarbon data from Marylebone Road
hc <- importUKAQ(site = "my1", year = 2008, hc = TRUE)

## Import data from the AQE network (York data in this case)
yk13 <- importUKAQ(site = "yk13", year = 2018, source = "aqe")

## Import data from the AURN *and* AQE network!
duo <- importUKAQ(site = c("my1", "yk13"), year = 2020, source = c("aurn", "aqe"))
```

也可以将站点的元数据和监测数据一起合并导出：

```{r}
#| label: importWithMeta
kc1 <- importUKAQ(site = "kc1", year = 2018, meta = TRUE)

glimpse(kc1)
```

数据获取类的函数在缺省状态下会将每一项污染物的数据作为一个单独的列。也可以通过 `to_narrow` 选项范围符合 *tidy* 规范的长数据（一列为污染物名称，一列为污染物浓度）：

```{r}
#| eval: false
my1 <- importUKAQ("my1", year = 2018, to_narrow = TRUE)
```

It is also possible to return information on whether the data have been
ratified or not using the option `ratified` (`FALSE` by default). So,
add the option `ratified = TRUE` if you want this information.

`ratified` 的开关选项可以选择是否返回审核状态信息（缺省为 `FALSE` ）。所以可以通过打开该选项 `ratified = TRUE` 来同时获得审核状态信息。 

### 地方监测网络

当使用**本地监测网络数据**的时候，通常有必要先了解以下这些数据的提供者信息。

```{r}
# access local meta data to get provider
meta_local <- importMeta("local", all = TRUE)
unique(meta_local$provider)
```

## 在地图上展示监测站点

为了简单的绘制整个监测网的站点地图，请考虑使用[openairmaps]{.pkg} R 包。这个包可以像安装 [openair]{.pkg} 一样从CRAN安装。

```{r}
#| eval: false
install.packages("openairmaps")
```

[openairmaps]{.pkg} 包中的 `networkMap()` 函数可以把 `importMeta()` 的结果包装生成下面实例中的站点地图。站点地图还可以进行多项定制，如站点是否在相互遮挡的情况下聚簇显示；是否包含可以筛选站点的控制面板（如按照站点类型进行删选）。

```{r}
#| label: fig-openairmapsNetworkMap
#| cache: false
#| fig-cap: Plotting the AURN using the `openairmaps` package.
#| results: asis
library(openairmaps)
networkMap(source = "aurn", control = "site_type")
```

[Network Visualisation Page](../maps/maps-network.qmd) 将介绍关于使用[openairmaps]{.pkg} 绘制监测网地图的更多详细信息。 

## 年均值等统计选项

所有监测数据获取类的函数默认返回小时数据，但是很多时候我们需要的可能只是年均值。为此`importUKAQ()`函数（除`importKCL`）添加了可以返回不同平均时间的数据，如年均、月均、日均以及 SO~2~ 的15分钟平均等。其中年均和月均的数据还包含了数据比较重要的数据捕获率的信息。这个平均时间由 `data_type` 选项，可以选择的值如下：

-   **"hourly"** 小时数据是默认选项，这里必须提供站点清单。
-   **"daily"** 返回一个或多个指定站点的日均值。注意 PM~10~ 和 PM~2.5~ 的日数据有可能来自小时分辨率的连续监测方法（使用TEOM、BAM和FIDAS等方法的监测仪器)，也有可能来自每日的称重法监测数据，如Partisol采样器。称重法的日数据会表示为 `gr_pm10` and `gr_pm2.5`。
-   **"monthly"** 返回月均值，不需要提供站点编码。指定年份的所有站点结果连同数据数据捕获率会一起返回。
-   **"annual"** 返回年均值，不需要提供站点编码。指定年份的所有站点结果连同数据数据捕获率会一起返回。
-   **"15_min"** 返回指定站点的 SO~2~ 的15分钟平均浓度。
-   **"8_hour"** 返回指定站点 O~3~ 和 CO 的8小时滑动平均浓度。
-   **"24_hour"** 返回指定站点 PM~10~ 和 PM~2.5~ 的24小时滑动平均浓度。
-   **"daily_max_8"** 范围 O~3~ 和 CO 的每日最大8小时滑动平均值。
-   **"daqi"** 返回每日空气质量指数(DAQI)。关于空气质量指数的定义和更多信息请访问[这里](https://uk-air.defra.gov.uk/air-pollution/daqi?view=more-info&pollutant=ozone#pollutant)。

请注意当指定返回年和月统计结果时会返回该监测网的全部数据， `site` 选择会被屏蔽。

例如：要导入AURN监测获取5年期间的年均值：

```{r}
#| eval: false
uk_annual <- importUKAQ(year = 2016:2020, data_type = "annual", source = "AURN")
```

上面的代码默认会得到“宽”数据，即每项污染物的数据独立占用一列。在更多情况下，使用 `to_narrow` 选项得到的“窄”数据更好用一些。另外如前文所述，站点的元数据（站点类型和经纬度等）也可以一并获取。

下面的代码可得到2020年的年均值“窄”数据，含元数据。

```{r}
#| label: importAnnual
uk_2020 <- importUKAQ(
  year = 2020,
  source = "aurn",
  data_type = "annual",
  meta = TRUE,
  to_narrow = TRUE
)

uk_2020
```

数据中涉及的污染物包括：

```{r}
unique(uk_2020$species)
```

得到2020年的年均值数据后，可以很方便的进一步增加污染物为 NO~2~ 和数据捕获率大于80%两个筛选条件：

```{r}
#| label: filterNO2
uk_2020 %>%
  filter(species == "no2", data_capture >= 0.8)
```

对于AURN国家网，还可以按照污染物得到每日的空气质量指数（DAQI）。

```{r}
#| label: daqi
daqi_2020 <- importUKAQ(
  year = 2020,
  source = "aurn",
  data_type = "daqi",
  meta = TRUE
)

daqi_2020
```
